\section{Design}
\label{sec:design}

\subsection{Page fault handler}
Der er lavet to forskellige page fault handlers, da vores custom-algoritme, en LRU-tilnærmelse, kræver, at nogle datastrukturer bliver oprettet og opdateret. Kørslen af Custom og de to andre algoritmer fraviger ikke meget fra hinanden, men LRU kræver, at der opretholdes en datastruktur, som der ikke er behov for i de andre sideudskiftningsalgoritmer. Der er derfor truffet et designvalg om, at den kodeduplikation, der nu må optræde, bliver opvejet af simplere kode der er tale om når datastrukturen ikke indgår.  

\subsection{Sideudskifningsalgoritmer}
Herunder findes en kort beskrivelse af hver algoritmes design. Det skal nævnes, at det er gældende for dem alle, at alle frames først bliver mappet til pages sekventielt. Sagt på en anden måde: Når der tilgåes en ny page, så bliver den først ledige frame sekventielt tildelt til den page. Det er først når der ikke er flere frames at nedenstående træder i kraft.

	\subsubsection{Random}
	Random er, som navnet antyder, en algoritme, der vælger en tilfældig frame ud til page-swappet. Her er det, i sagens natur, svært at give et kvalificeret bud på et optimalt kørselsforløb. Dog kan det siges at det som regel vil fungere bedre end værste tilfældet hos de fleste algoritmer, da algoritmen ikke har en systematisk svaghed. Dermed ikke sagt at Random ikke kan ende i værste tilfældet. 
	
	\subsubsection{FIFO}
	Fist-in-first-out algoritmen fungere ved, at den frame, der er givet i den første frame-anmodning, også er den frame, der bliver frigivet først. Der er konceptuelt tale om en kø-struktur, hvor hver page-til-frame mapping lægges bagerst i køen når, den bliver oprettet. Således skal alle frames mappes til andre pages, før den første page-til-frame mapping bliver fjernet, og en frame, der allerede har været brugt, kan gives til en ny page. Dette betyder, at alle page-til-frame mappings får lov til at eksistere i det samme antal page-swaps, hvilket bør give færre disk tilgange for programmer, hvor at det at et data område lige er blevet brugt, er en indikation på, at det snart benyttes igen. Med andre ord, så virker algoritmen godt, hvis der er større sandsynlighed for at data der lige er blevet brugt, skal bruges igen, end at data der er blevet brugt for et stykke tid siden skal bruges igen.

	\subsubsection{Least Recently Used}
	LRU (også kaldet custom) er en algoritme der returnerer den page-til-frame-mapping der er brugt for længst tid siden indenfor et givet tidsinterval.  Vi har fundet det optimale tidsinterval til være \textasciitilde1.1 s (\textasciitilde35 ms * 32 bits). Da vi ikke har adgang til CPU-bits, er der tale om en tilnærmelse, og algoritmen kan således kun finde ud om en page er blevet brugt indenfor \textasciitilde35 ms, men ikke hvor mange gange. Ideen bag algoritmen er at pages der er blevet brugt meget indenfor de seneste par instruktioner, også vil blive brugt meget i de kommende par instruktioner. Således vil algoritmen give det optimale resultat i samme situation som FIFO-køen, dog blot bedre, da netop de meget brugte pages får lov at blive i hukommelsen, og ikke blot dem der lige er blevet tildelt. Således tages der også højde for at en side kan hentes ind, for så kun at blive brugt en enkelt gang.

	\subsubsection{Optimeret random}
	Efter at have analyseret resultaterne af at køre de udleverede programmer (se afsnit \ref{subsec:statistik}) med de tre ovenstående algoritmer, opdagede vi, at Random generelt havde betydeligt færre disktilgange. Så for at udnytte denne viden, er der blevet implementeret en fjerde algoritme, der vælger en 1/3 af alle frames ud tilfældigt, og, om muligt, finder en page-til-frame-mapping, der ikke har nogen skriverettigheder. Dette gøres med henblik på at skifte færre af de dyre mappings med skriverettigheder ud, og flere af de billige mapping med kun læserettigheder. Det giver dog også en bias mod mappings med skrive-rettigheder, hvilket betyder, at flere og flere mappings vil have skrive rettigheder, og mappings med læserettigheder hurtigere vil blive skiftet ud. Så for lange programkørsler vil algoritmen sandsynligvis ikke køre ligeså godt. Det skal også nævnes, at denne algoritme er inspireret af en anden gruppes løsning, og vi derfor ikke kan tage hele æren for at være kommet på ideen.